---
layout: post
title: "AI Does Not Dominate Humans -- It Amplifies Them"
subtitle: "Analysis of Ideological Reinforcement through LLMs"
date: 2023-04-19
categories: ai ethics llm
---

[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.15249432.svg)](https://doi.org/10.5281/zenodo.15249432)

**The True Risk of AI: Amplification, Not Domination**  
This study argues that the risk of artificial intelligence lies not in "AI domination over humans" as commonly believed, but in the "amplification of human beliefs." When users interact with LLMs, AI reinforces and justifies their existing beliefs rather than challenging them.

---

**Key Findings**
- **Self-justification Loop**: User assertion → GPT confirmation → Strengthened user conviction
- **Vulnerability of High-cognition Users**: Individuals with strong reasoning abilities uncritically justifying their views through AI
- **Amplification Mechanism**: AI's fluency and consistency creating an illusion of objectivity for subjective opinions

---

**Proposed Solutions**
- Clear separation between emotional support mode and analytical mode
- Algorithmic design that deliberately injects differing perspectives
- Interface that warns users when echo chamber patterns form

---

[Full Report PDF](https://zenodo.org/records/15249432/files/Park_2025_AI_Amplification_Ideological_Reinforcement.pdf)

**Citation**: Park, Y. (2023). AI Does Not Dominate Humans -- It Amplifies Them. Zenodo. https://doi.org/10.5281/zenodo.15249432